BDEPEND=test? ( dev-python/six[python_targets_python3_10(-)?,python_targets_python3_11(-)?] python_targets_python3_10? ( dev-python/unittest-or-fail[python_targets_python3_10(-)?,python_targets_python3_11(-)?] ) python_targets_python3_11? ( dev-python/unittest-or-fail[python_targets_python3_10(-)?,python_targets_python3_11(-)?] ) ) python_targets_python3_10? ( dev-lang/python:3.10 ) python_targets_python3_11? ( dev-lang/python:3.11 ) >=dev-python/setuptools-67.8.0-r1[python_targets_python3_10(-)?,python_targets_python3_11(-)?]
DEFINED_PHASES=compile configure install prepare test
DESCRIPTION=Module to detect if a given HTTP User Agent is a web crawler
EAPI=8
HOMEPAGE=https://github.com/rory/robot-detection
INHERIT=distutils-r1
IUSE=test python_targets_python3_10 python_targets_python3_11
KEYWORDS=~amd64
LICENSE=GPL-3
RDEPEND=dev-python/six[python_targets_python3_10(-)?,python_targets_python3_11(-)?] python_targets_python3_10? ( dev-lang/python:3.10 ) python_targets_python3_11? ( dev-lang/python:3.11 )
REQUIRED_USE=|| ( python_targets_python3_10 python_targets_python3_11 )
RESTRICT=!test? ( test )
SLOT=0
SRC_URI=https://github.com/rory/robot-detection/archive/v0.4.0.tar.gz -> robot-detection-0.4.0.tar.gz
_eclasses_=toolchain-funcs	e56c7649b804f051623c8bc1a1c44084	multilib	c19072c3cd7ac5cb21de013f7e9832e0	flag-o-matic	24c947ff5f858625cf0b33c15eed4425	out-of-source-utils	1a9007554652a6e627edbccb3c25a439	multibuild	d67e78a235f541871c7dfe4cf7931489	multiprocessing	30ead54fa2e2b5f9cd4e612ffc34d0fe	ninja-utils	2df4e452cea39a9ec8fb543ce059f8d6	python-utils-r1	8904b60325f22500b0c3ad4b68a42448	python-r1	8a28fa6d3e3bc96ff8a7eff2badbe71f	distutils-r1	ecb6da69bf4eb19761b48d6d3889c23a
_md5_=b8e0e183779254e693c4874c529fbd5e
